{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Weather Forecasting using a Long Short-Term Memory (LSTM) Network\n",
    "\n",
    "**Copyright (c) 2026 Shrikara Kaudambady. All rights reserved.**\n",
    "\n",
    "This notebook demonstrates how to build and train an LSTM Recurrent Neural Network (RNN) for time-series weather forecasting. We will predict the future temperature based on a sequence of past weather conditions (temperature, humidity, and pressure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Simulation\n",
    "\n",
    "We will generate a synthetic multi-variate weather dataset with hourly readings for 3 years. This includes temperature, humidity, and pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "time_index = pd.date_range(start='2023-01-01', end='2025-12-31 23:00:00', freq='h')\n",
    "num_hours = len(time_index)\n",
    "\n",
    "# Temperature: Seasonal + Daily variation + Noise\n",
    "seasonal_temp = 15 * (1 - np.cos(2 * np.pi * time_index.dayofyear / 365.25))\n",
    "daily_temp = 5 * (1 - np.cos(2 * np.pi * time_index.hour / 24))\n",
    "temperature = seasonal_temp + daily_temp + np.random.normal(0, 1.5, num_hours) + 5 # Base temp of 5C\n",
    "\n",
    "# Humidity: Inversely related to temperature + Noise\n",
    "humidity = 80 - (temperature * 1.5) + np.random.normal(0, 5, num_hours)\n",
    "humidity = np.clip(humidity, 20, 100)\n",
    "\n",
    "# Pressure: Stable with some noise\n",
    "pressure = 1013 + np.random.normal(0, 2, num_hours)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'temperature': temperature,\n",
    "    'humidity': humidity,\n",
    "    'pressure': pressure\n",
    "}, index=time_index)\n",
    "\n",
    "print(\"Simulated Weather Data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing for LSTM\n",
    "\n",
    "Neural networks require special data preparation:\n",
    "1.  **Scaling:** All features must be scaled to a uniform range (e.g., 0 to 1).\n",
    "2.  **Sequencing:** The data must be converted into windows of sequences (X) and corresponding target values (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Step 2: Create sequences\n",
    "# We will use the last 72 hours (3 days) of data to predict the temperature in 12 hours.\n",
    "N_PAST = 72  # Number of past hours to use as input\n",
    "N_FUTURE = 12 # Number of hours in the future to predict\n",
    "N_FEATURES = df.shape[1]\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(N_PAST, len(df_scaled) - N_FUTURE + 1):\n",
    "    X.append(df_scaled[i - N_PAST:i, 0:N_FEATURES])\n",
    "    y.append(df_scaled[i + N_FUTURE - 1:i + N_FUTURE, 0]) # Predicting temperature\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split into training and testing sets (80/20 split)\n",
    "split_ratio = 0.8\n",
    "split_point = int(split_ratio * len(X))\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build and Train the LSTM Model\n",
    "\n",
    "We will now define our LSTM model architecture using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(50, activation='relu', input_shape=(N_PAST, N_FEATURES), return_sequences=False),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation and Visualization\n",
    "\n",
    "Let's see how well our model performs by predicting on the test set and comparing the forecast to the actual temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse scale the predictions to get actual temperature values\n",
    "# We need to create a dummy array with the same shape as the original scaler input\n",
    "dummy_array = np.zeros((len(predictions_scaled), N_FEATURES))\n",
    "dummy_array[:, 0] = predictions_scaled.flatten()\n",
    "predictions = scaler.inverse_transform(dummy_array)[:, 0]\n",
    "\n",
    "# Inverse scale the actual values for comparison\n",
    "dummy_array_actual = np.zeros((len(y_test), N_FEATURES))\n",
    "dummy_array_actual[:, 0] = y_test.flatten()\n",
    "actuals = scaler.inverse_transform(dummy_array_actual)[:, 0]\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual Temperature': actuals,\n",
    "    'Predicted Temperature': predictions\n",
    "}, index=df.index[split_point + N_PAST + N_FUTURE - 1:])\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(16, 8))\n",
    "plot_df['Actual Temperature'].tail(200).plot(label='Actual', lw=2)\n",
    "plot_df['Predicted Temperature'].tail(200).plot(label='Predicted', lw=2, style='--')\n",
    "plt.title('Weather Forecast vs. Actual (Last 200 Hours of Test Set)')\n",
    "plt.ylabel('Temperature (Â°C)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}